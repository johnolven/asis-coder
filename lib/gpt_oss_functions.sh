# =======================================================
# FUNCIONES COMPLEMENTARIAS PARA GPT-OSS-20B
# =======================================================

# FunciÃ³n para mostrar UI de descarga de gpt-oss-20b
show_gpt_oss_download_ui() {
    local CYAN='\033[0;36m'
    local GREEN='\033[0;32m'
    local YELLOW='\033[1;33m'
    local PURPLE='\033[0;35m'
    local BLUE='\033[0;34m'
    local BOLD='\033[1m'
    local DIM='\033[2m'
    local NC='\033[0m'
    
    clear
    echo -e "${CYAN}${BOLD}ðŸŒŸ DESCARGA DE GPT-OSS-20B${NC}"
    echo -e "${YELLOW}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    echo -e "${GREEN}ðŸ“‹ InformaciÃ³n del Modelo:${NC}"
    echo -e "   ${CYAN}â€¢${NC} ${BOLD}Nombre:${NC} gpt-oss-20b"
    echo -e "   ${CYAN}â€¢${NC} ${BOLD}TamaÃ±o:${NC} 21B parÃ¡metros (3.6B activos)"
    echo -e "   ${CYAN}â€¢${NC} ${BOLD}Licencia:${NC} Apache 2.0 (CÃ³digo Abierto)"
    echo -e "   ${CYAN}â€¢${NC} ${BOLD}CaracterÃ­sticas:${NC} Razonamiento avanzado, Capacidades agenticas"
    echo -e "   ${CYAN}â€¢${NC} ${BOLD}Memoria requerida:${NC} ~16GB RAM"
    echo ""
    
    echo -e "${BLUE}${BOLD}ðŸ› ï¸ MÃ©todos de Descarga Disponibles:${NC}"
    echo -e "${DIM}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo ""
    
    # Verificar quÃ© herramientas estÃ¡n disponibles
    local ollama_available=false
    local hf_cli_available=false
    local lm_studio_available=false
    local option_count=0
    
    if command -v ollama >/dev/null 2>&1; then
        ollama_available=true
        option_count=$((option_count + 1))
        echo -e "${GREEN}${option_count}. ${BOLD}Ollama${NC} ${DIM}(Recomendado)${NC}"
        echo -e "   ${CYAN}â€¢${NC} FÃ¡cil de usar, optimizado para consumidores"
        echo -e "   ${CYAN}â€¢${NC} GestiÃ³n automÃ¡tica de memoria"
        echo -e "   ${CYAN}â€¢${NC} Comando: ${YELLOW}ollama pull gpt-oss:20b${NC}"
        echo ""
    fi
    
    if command -v huggingface-cli >/dev/null 2>&1; then
        hf_cli_available=true
        option_count=$((option_count + 1))
        echo -e "${PURPLE}${option_count}. ${BOLD}Hugging Face CLI${NC} ${DIM}(Desarrolladores)${NC}"
        echo -e "   ${CYAN}â€¢${NC} Acceso directo a modelos HF"
        echo -e "   ${CYAN}â€¢${NC} MÃ¡s control sobre la descarga"
        echo -e "   ${CYAN}â€¢${NC} Comando: ${YELLOW}huggingface-cli download openai/gpt-oss-20b${NC}"
        echo ""
    fi
    
    # LM Studio (verificar si existe)
    if command -v lms >/dev/null 2>&1; then
        lm_studio_available=true
        option_count=$((option_count + 1))
        echo -e "${BLUE}${option_count}. ${BOLD}LM Studio${NC} ${DIM}(Interfaz GrÃ¡fica)${NC}"
        echo -e "   ${CYAN}â€¢${NC} Interfaz grÃ¡fica amigable"
        echo -e "   ${CYAN}â€¢${NC} GestiÃ³n visual de modelos"
        echo -e "   ${CYAN}â€¢${NC} Comando: ${YELLOW}lms get openai/gpt-oss-20b${NC}"
        echo ""
    fi
    
    # OpciÃ³n de instalaciÃ³n manual
    option_count=$((option_count + 1))
    echo -e "${YELLOW}${option_count}. ${BOLD}InstalaciÃ³n Manual${NC} ${DIM}(Avanzado)${NC}"
    echo -e "   ${CYAN}â€¢${NC} Descarga directa desde Hugging Face"
    echo -e "   ${CYAN}â€¢${NC} Control total del proceso"
    echo -e "   ${CYAN}â€¢${NC} Requiere configuraciÃ³n adicional"
    echo ""
    
    option_count=$((option_count + 1))
    echo -e "${DIM}${option_count}. Cancelar${NC}"
    echo ""
    
    echo -e "${YELLOW}âš ï¸ Notas Importantes:${NC}"
    echo -e "   ${CYAN}â€¢${NC} El modelo requiere aproximadamente ${BOLD}12-16GB${NC} de espacio en disco"
    echo -e "   ${CYAN}â€¢${NC} La descarga puede tomar ${BOLD}10-30 minutos${NC} dependiendo de tu conexiÃ³n"
    echo -e "   ${CYAN}â€¢${NC} Se recomienda una conexiÃ³n estable para evitar interrupciones"
    echo ""
    echo -e "${DIM}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    
    while true; do
        read -p "$(echo -e "${CYAN}Selecciona el mÃ©todo de descarga (1-$option_count): ${NC}")" download_choice
        
        case $download_choice in
            1)
                if $ollama_available; then
                    download_gpt_oss_ollama
                    return $?
                elif $hf_cli_available; then
                    download_gpt_oss_hf_cli
                    return $?
                elif $lm_studio_available; then
                    download_gpt_oss_lm_studio
                    return $?
                else
                    download_gpt_oss_manual
                    return $?
                fi
                ;;
            2)
                if $ollama_available && $hf_cli_available; then
                    download_gpt_oss_hf_cli
                    return $?
                elif $ollama_available && $lm_studio_available; then
                    download_gpt_oss_lm_studio
                    return $?
                elif $hf_cli_available; then
                    download_gpt_oss_manual
                    return $?
                else
                    download_gpt_oss_manual
                    return $?
                fi
                ;;
            3)
                if $ollama_available && $hf_cli_available && $lm_studio_available; then
                    download_gpt_oss_lm_studio
                    return $?
                elif ($ollama_available && $hf_cli_available) || ($ollama_available && $lm_studio_available) || ($hf_cli_available && $lm_studio_available); then
                    download_gpt_oss_manual
                    return $?
                else
                    echo -e "${YELLOW}â¹ï¸ Descarga cancelada${NC}"
                    return 1
                fi
                ;;
            4)
                if $ollama_available && $hf_cli_available && $lm_studio_available; then
                    download_gpt_oss_manual
                    return $?
                else
                    echo -e "${YELLOW}â¹ï¸ Descarga cancelada${NC}"
                    return 1
                fi
                ;;
            5)
                echo -e "${YELLOW}â¹ï¸ Descarga cancelada${NC}"
                return 1
                ;;
            *)
                echo -e "${YELLOW}âŒ OpciÃ³n no vÃ¡lida. Selecciona entre 1-$option_count${NC}"
                ;;
        esac
    done
}

# FunciÃ³n para descargar con Ollama
download_gpt_oss_ollama() {
    local GREEN='\033[0;32m'
    local CYAN='\033[0;36m'
    local YELLOW='\033[1;33m'
    local RED='\033[0;31m'
    local BOLD='\033[1m'
    local NC='\033[0m'
    
    echo -e "${CYAN}${BOLD}ðŸ‹ Descargando gpt-oss-20b con Ollama...${NC}"
    echo -e "${YELLOW}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo ""
    
    echo -e "${CYAN}ðŸ“¥ Iniciando descarga...${NC}"
    echo -e "${YELLOW}ðŸ’¡ Esto puede tomar varios minutos. Por favor espera...${NC}"
    echo ""
    
    # Ejecutar ollama pull con feedback visual
    if ollama pull gpt-oss:20b; then
        echo ""
        echo -e "${GREEN}âœ… gpt-oss-20b descargado exitosamente con Ollama${NC}"
        echo -e "${CYAN}ðŸš€ Puedes usar el modelo con: ${YELLOW}ollama run gpt-oss:20b${NC}"
        return 0
    else
        echo ""
        echo -e "${RED}âŒ Error durante la descarga con Ollama${NC}"
        echo -e "${YELLOW}ðŸ’¡ Verifica tu conexiÃ³n a internet e intenta nuevamente${NC}"
        return 1
    fi
}

# FunciÃ³n para descargar con Hugging Face CLI
download_gpt_oss_hf_cli() {
    local GREEN='\033[0;32m'
    local CYAN='\033[0;36m'
    local YELLOW='\033[1;33m'
    local RED='\033[0;31m'
    local BOLD='\033[1m'
    local NC='\033[0m'
    
    echo -e "${CYAN}${BOLD}ðŸ¤— Descargando gpt-oss-20b con Hugging Face CLI...${NC}"
    echo -e "${YELLOW}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo ""
    
    echo -e "${CYAN}ðŸ“¥ Iniciando descarga desde Hugging Face...${NC}"
    echo -e "${YELLOW}ðŸ’¡ Descargando archivos del modelo...${NC}"
    echo ""
    
    # Crear directorio local para el modelo
    local model_dir="$HOME/.local/share/asis-coder/models/gpt-oss-20b"
    mkdir -p "$model_dir"
    
    # Ejecutar descarga
    if huggingface-cli download openai/gpt-oss-20b --include "original/*" --local-dir "$model_dir"; then
        echo ""
        echo -e "${GREEN}âœ… gpt-oss-20b descargado exitosamente${NC}"
        echo -e "${CYAN}ðŸ“ UbicaciÃ³n: ${YELLOW}$model_dir${NC}"
        return 0
    else
        echo ""
        echo -e "${RED}âŒ Error durante la descarga${NC}"
        echo -e "${YELLOW}ðŸ’¡ Verifica tu conexiÃ³n e intenta nuevamente${NC}"
        return 1
    fi
}

# FunciÃ³n para descargar con LM Studio
download_gpt_oss_lm_studio() {
    local GREEN='\033[0;32m'
    local CYAN='\033[0;36m'
    local YELLOW='\033[1;33m'
    local RED='\033[0;31m'
    local BOLD='\033[1m'
    local NC='\033[0m'
    
    echo -e "${CYAN}${BOLD}ðŸŽ¨ Descargando gpt-oss-20b con LM Studio...${NC}"
    echo -e "${YELLOW}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo ""
    
    echo -e "${CYAN}ðŸ“¥ Iniciando descarga con LM Studio...${NC}"
    echo ""
    
    if lms get openai/gpt-oss-20b; then
        echo ""
        echo -e "${GREEN}âœ… gpt-oss-20b descargado exitosamente con LM Studio${NC}"
        echo -e "${CYAN}ðŸ’¡ Puedes gestionar el modelo desde la interfaz de LM Studio${NC}"
        return 0
    else
        echo ""
        echo -e "${RED}âŒ Error durante la descarga con LM Studio${NC}"
        return 1
    fi
}

# FunciÃ³n para instalaciÃ³n manual
download_gpt_oss_manual() {
    local GREEN='\033[0;32m'
    local CYAN='\033[0;36m'
    local YELLOW='\033[1;33m'
    local RED='\033[0;31m'
    local BLUE='\033[0;34m'
    local BOLD='\033[1m'
    local NC='\033[0m'
    
    echo -e "${BLUE}${BOLD}âš™ï¸ InstalaciÃ³n Manual de gpt-oss-20b${NC}"
    echo -e "${YELLOW}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    
    echo -e "${YELLOW}ðŸ“‹ Instrucciones para instalaciÃ³n manual:${NC}"
    echo ""
    echo -e "${CYAN}${BOLD}OpciÃ³n 1: Instalar Ollama (Recomendado)${NC}"
    echo -e "   ${CYAN}1.${NC} Visita: ${YELLOW}https://ollama.com${NC}"
    echo -e "   ${CYAN}2.${NC} Descarga e instala Ollama para tu sistema"
    echo -e "   ${CYAN}3.${NC} Ejecuta: ${YELLOW}ollama pull gpt-oss:20b${NC}"
    echo ""
    
    echo -e "${CYAN}${BOLD}OpciÃ³n 2: Instalar Hugging Face CLI${NC}"
    echo -e "   ${CYAN}1.${NC} Instala: ${YELLOW}pip install huggingface_hub[cli]${NC}"
    echo -e "   ${CYAN}2.${NC} Ejecuta: ${YELLOW}huggingface-cli download openai/gpt-oss-20b${NC}"
    echo ""
    
    echo -e "${CYAN}${BOLD}OpciÃ³n 3: Usar con Transformers${NC}"
    echo -e "   ${CYAN}1.${NC} Instala: ${YELLOW}pip install transformers torch${NC}"
    echo -e "   ${CYAN}2.${NC} Usa en Python:"
    echo -e "      ${YELLOW}from transformers import pipeline${NC}"
    echo -e "      ${YELLOW}pipe = pipeline('text-generation', 'openai/gpt-oss-20b')${NC}"
    echo ""
    
    echo -e "${GREEN}ðŸ’¡ DespuÃ©s de instalar, ejecuta nuevamente:${NC}"
    echo -e "   ${YELLOW}coder -model${NC}"
    echo ""
    
    read -p "$(echo -e "${CYAN}Â¿Quieres abrir la documentaciÃ³n oficial? (y/n): ${NC}")" open_docs
    
    if [[ "$open_docs" =~ ^[Yy]$ ]]; then
        if command -v open >/dev/null 2>&1; then
            open "https://huggingface.co/openai/gpt-oss-20b"
        elif command -v xdg-open >/dev/null 2>&1; then
            xdg-open "https://huggingface.co/openai/gpt-oss-20b"
        else
            echo -e "${CYAN}ðŸ“– DocumentaciÃ³n: ${YELLOW}https://huggingface.co/openai/gpt-oss-20b${NC}"
        fi
    fi
    
    return 1  # Manual installation requires user action
}
